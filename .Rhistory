)
check_data(df_temp)
df_temp <- as.data.frame(df_temp) %>%
plot(.$ac)
df_temp <- as.data.frame(df_temp) %>%
mutate(
ac = as.numeric(ac),
minsplit = as.numeric(minsplit),
minbucket = as.numeric(minbucket),
maxdepth = as.numeric(maxdepth)
) %>%
plot(.$ac)
df_temp <- as.data.frame(df_temp) %>%
mutate(
ac = as.numeric(ac),
minsplit = as.numeric(minsplit),
minbucket = as.numeric(minbucket),
maxdepth = as.numeric(maxdepth)
)
df_temp <- as.data.frame(df_temp) %>%
mutate(.,
ac = as.numeric(ac),
minsplit = as.numeric(minsplit),
minbucket = as.numeric(minbucket),
maxdepth = as.numeric(maxdepth)
)
df_temp <- as.data.frame(df_temp) %>%
mutate(
ac = as.numeric(df_temp$ac),
minsplit = as.numeric(minsplit),
minbucket = as.numeric(minbucket),
maxdepth = as.numeric(maxdepth)
)
df_temp <- as.data.frame(df_temp) %>%
mutate(
ac = as.numeric(df_temp$ac),
minsplit = as.numeric(df_temp$minsplit),
minbucket = as.numeric(df_temp$minbucket),
maxdepth = as.numeric(df_temp$maxdepth)
)
plot(df_temp$ac)
plot(df_temp)
check_data(df_temp)
# Tune model
df_temp <- NULL
# Tune model
df_temp <- as.data.frame(NULL)
rownum <- 1
pb <- new_pb(10^3)
for(i in 1:10) {
for(j in 1:10){
for(k in 1:10) {
pb$tick()
control <- rpart.control(
minsplit = i,
minbucket = j,
maxdepth = k,
cp = 0
)
tune_fit <- rpart(hasJAS~., data = data_train, method = 'class', control = control)
ac <- accuracy_tune(tune_fit)
df_temp$ac[rownum] = ac
df_temp$minsplit[rownum] = i
df_temp$minbucket[rownum] = j
df_temp$maxdepth[rownum] = k
rownum <- rownum + 1
}
}
}
# Tune model
df_temp <- as.data.frame(NULL)
rownum <- 1
pb <- new_pb(10^3)
for(i in 1:10) {
for(j in 1:10){
for(k in 1:10) {
pb$tick()
control <- rpart.control(
minsplit = i,
minbucket = j,
maxdepth = k,
cp = 0
)
tune_fit <- rpart(hasJAS~., data = data_train, method = 'class', control = control)
ac <- accuracy_tune(tune_fit)
df_temp$ac[rownum] = ac
df_temp$minsplit[rownum] = i
df_temp$minbucket[rownum] = j
df_temp$maxdepth[rownum] = k
rownum <- rownum + 1
}
}
}
# Tune model
df_temp <- as.data.frame()
rownum <- 1
pb <- new_pb(10^3)
for(i in 1:10) {
for(j in 1:10){
for(k in 1:10) {
pb$tick()
control <- rpart.control(
minsplit = i,
minbucket = j,
maxdepth = k,
cp = 0
)
tune_fit <- rpart(hasJAS~., data = data_train, method = 'class', control = control)
ac <- accuracy_tune(tune_fit)
df_temp$ac[rownum] = ac
df_temp$minsplit[rownum] = i
df_temp$minbucket[rownum] = j
df_temp$maxdepth[rownum] = k
rownum <- rownum + 1
}
}
}
# Tune model
df_temp <- NULL
rownum <- 1
pb <- new_pb(10^3)
for(i in 1:10) {
for(j in 1:10){
for(k in 1:10) {
pb$tick()
control <- rpart.control(
minsplit = i,
minbucket = j,
maxdepth = k,
cp = 0
)
tune_fit <- rpart(hasJAS~., data = data_train, method = 'class', control = control)
ac <- accuracy_tune(tune_fit)
df_temp$ac[rownum] = ac
df_temp$minsplit[rownum] = i
df_temp$minbucket[rownum] = j
df_temp$maxdepth[rownum] = k
rownum <- rownum + 1
}
}
}
new_pb <- function(total)  {
progress_bar$new(
format = "(:spin) [:bar] :percent [Elaspsed time: :elapsedfull || Estimated time remaining: :eta]",
total = total,
complete = "=",
incomplete = "-",
current = ">",
clear = FALSE,
width = 100
)
}
df_temp_raw <- df_temp
df_temp <- as.data.frame(df_temp)
plot(df_temp)
check_data(df_temp)
ggpairs(
df_temp,
mapping = aes(
color = ac, alpha = 0.6
),
lower = list(continuous = "smooth", combo = "facetdensity"),
diag = list(continuous = "barDiag")
)
ggpairs(
df_temp,
lower = list(continuous = "smooth", combo = "facetdensity"),
diag = list(continuous = "barDiag")
)
max(df_temp$ac)
df_max <- df[df_temp$ac == max(df_temp$ac)]
df_max <- df[df_temp$ac == max(df_temp$ac),]
df_max <- df_temp[df_temp$ac == max(df_temp$ac),]
df_max
max_ac <- max(df_temp$ac)
df_max <- df_temp[df_temp$ac == max_ac,]
plot_rows <- ceiling( sqrt( nrow( df_max)))
plot_rows <- ceiling( sqrt( nrow( df_max)))
plot_col <- ceiling(nrow(df_temp)/ plot_rows)
plot_rows <- ceiling( sqrt( nrow( df_max)))
plot_col <- ceiling(nrow(df_max)/ plot_rows)
plot_rows <- ceiling( sqrt( nrow( df_max)))
plot_cols <- ceiling(nrow(df_max)/ plot_rows)
par(mfrow = c(plot_rows, plot_cols))
for(i in nrow(df_max)) {
minsplit <- df_max$minsplit[i]
minbucket <- df_max$minbucket[i]
maxdepth <- df_max$maxdepth[i]
control <- rpart.control(
minsplit = minsplit,
minbucket = minbucket,
maxdepth = maxdepth,
cp = 0
)
tune_fit <- rpart(hasJAS~., data = data_train, method = 'class', control = control)
rpart.plot(tune_fit)
}
par(mfrow = c(1,1))
for(i in nrow(df_max)) {
minsplit <- df_max$minsplit[i]
minbucket <- df_max$minbucket[i]
maxdepth <- df_max$maxdepth[i]
control <- rpart.control(
minsplit = minsplit,
minbucket = minbucket,
maxdepth = maxdepth,
cp = 0
)
tune_fit <- rpart(hasJAS~., data = data_train, method = 'class', control = control)
rpart.plot(tune_fit)
}
check_data(df_max)
pred <- predict(tune_fit, data_test, type = 'class')
pred_mat <- table(data_test$hasGAP, pred)
pred_mat
pred_mat <- table(data_test$hasJAS, pred)
pred_mat
precision <- pred_mat(1,1) / sum(pred_mat(,1))
precision <- pred_mat[1,1] / sum(pred_mat(,1))
precision <- pred_mat[1,1] / sum(pred_mat[,1])
recall <- pred_mat[1,1] / sum(pred_mat[1,])
paste('precision: ', precision, '\nrecall: ', recall)
paste('precision:', precision, 'recall:', recall)
precision <- round(pred_mat[1,1] / sum(pred_mat[,1]))
recall <- round( pred_mat[1,1] / sum(pred_mat[1,]))
paste('precision:', precision, 'recall:', recall)
precision <- round(pred_mat[1,1] / sum(pred_mat[,1]), digits = 2)
recall <- round( pred_mat[1,1] / sum(pred_mat[1,]), digits = 2)
paste('precision:', precision, 'recall:', recall)
# library(dplyr) # Filtering and else
# library(formattable) # Table visualization
# library(wordcloud) # Create wordcloud
# library(data.table)
# library(jsonlite)
# library(purrr)
# library(progress)
# library(dplyr)
# library(rpart) ## Decision tree
# library(rpart.plot) ## Decision tree
library(caret)
confusionMatrix(pred, data_test$hasJAS, mode = 'everything', positive = "1")
confusionMatrix(pred, data_test$hasJAS, mode = 'everything', positive = "hasJAS")
confusionMatrix(pred, data_test$hasJAS, mode = 'everything', positive = "JAS")
confusionMatrix(pred, data_test$hasJAS, mode = 'everything', positive = "JAS")
# Shuffle data -----
check_data(df_products)
glimpse(df_products)
df_temp <- df_products %>%
select( -c("datetime", "pageNum", "product_id", "product", "producer_id", "producer", "area"))
shuffle_index <- sample(1:nrow(df_temp))
head(shuffle_index)
df_shuffled <- df_temp[shuffle_index,]
head(df_shuffled)
# Separate data for training and testing ----
data_train <- create_train_test(df_shuffled, 0.8, train = TRUE)
data_test <- create_train_test(df_shuffled, 0.8, train = FALSE)
dim(data_train)
dim(data_test)
prop.table(table(data_train$hasGAP))
prop.table(table(data_test$hasGAP))
# Build the model ----
fit <- rpart(hasJAS~., data = data_train, method = 'class')
rpart.plot(fit)
predict_unseen <- predict(fit,data_test, type = 'class')
table_mat <- table(data_test$hasJAS, predict_unseen)
table_mat
confusionMatrix(predict_unseen, data_test$hasJAS, mode = "everything", positive = "JAS")
# Tune model ----
df_temp <- NULL
rownum <- 1
pb <- new_pb(10^3)
for(i in 1:10) {
for(j in 1:10){
for(k in 1:10) {
pb$tick()
control <- rpart.control(
minsplit = i,
minbucket = j,
maxdepth = k,
cp = 0
)
tune_fit <- rpart(hasJAS~., data = data_train, method = 'class', control = control)
ac <- accuracy_tune(tune_fit)
df_temp$ac[rownum] = ac
df_temp$minsplit[rownum] = i
df_temp$minbucket[rownum] = j
df_temp$maxdepth[rownum] = k
rownum <- rownum + 1
}
}
}
df_temp_raw <- df_temp
df_temp <- as.data.frame(df_temp)
check_data(df_temp)
ggpairs(
df_temp,
lower = list(continuous = "smooth", combo = "facetdensity"),
diag = list(continuous = "barDiag")
)
max_ac <- max(df_temp$ac)
df_max <- df_temp[df_temp$ac == max_ac,]
# check_data(df_max)
for(i in nrow(df_max)) {
minsplit <- df_max$minsplit[i]
minbucket <- df_max$minbucket[i]
maxdepth <- df_max$maxdepth[i]
control <- rpart.control(
minsplit = minsplit,
minbucket = minbucket,
maxdepth = maxdepth,
cp = 0
)
tune_fit <- rpart(hasJAS~., data = data_train, method = 'class', control = control)
(rpart.plot(tune_fit))
}
# Confusion matrix ----
pred <- predict(tune_fit, data_test, type = 'class')
confusionMatrix(pred, data_test$hasJAS, mode = 'everything', positive = "JAS")
# Undersampling ----
df_udersampled <- ubBalance()
# library(formattable) # Table visualization
# library(wordcloud) # Create wordcloud
# library(data.table)
# library(jsonlite)
# library(purrr)
# library(progress)
# library(dplyr)
# library(rpart) ## Decision tree
# library(rpart.plot) ## Decision tree
# library(caret) #Create confusion matrix in machine learning
library(unbalanced)
# install.packages("igraph")
# install.packages("tidytext")
# install.packages("pastecs")
# install.packages("psych")
# install.packages("wordcloud")
# install.packages("GGally")
# install.packages("RMeCab", repos = "https://rmecab.jp/R", type = "source")
# install.packages("formattable" , dependencies = T)
# install.packages("wordcloud", dependencies = T)
# install.packages("rpart.plot")
install.packages("unbalanced")
# library(formattable) # Table visualization
# library(wordcloud) # Create wordcloud
# library(data.table)
# library(jsonlite)
# library(purrr)
# library(progress)
# library(dplyr)
# library(rpart) ## Decision tree
# library(rpart.plot) ## Decision tree
# library(caret) #Create confusion matrix in machine learning
library(unbalanced)
# install.packages("igraph")
# install.packages("tidytext")
# install.packages("pastecs")
# install.packages("psych")
# install.packages("wordcloud")
# install.packages("GGally")
# install.packages("RMeCab", repos = "https://rmecab.jp/R", type = "source")
# install.packages("formattable" , dependencies = T)
# install.packages("wordcloud", dependencies = T)
# install.packages("rpart.plot")
install.packages("ROSE")
# library(wordcloud) # Create wordcloud
# library(data.table)
# library(jsonlite)
# library(purrr)
# library(progress)
# library(dplyr)
# library(rpart) ## Decision tree
# library(rpart.plot) ## Decision tree
# library(caret) #Create confusion matrix in machine learning
# library(unbalanced)
library(ROSE)
# Undersampling ----
df_udersampled <- ovun.sample(
hasJAS~.,
data = data_train,
N = nrow(data_train),
p = 0.5,
seed = 1,
method = "both"
)
# Undersampling ----
df_balanced <- ovun.sample(
hasJAS~.,
data = data_train,
N = nrow(data_train),
p = 0.5,
seed = 1,
method = "both"
)
df_balanced
check_data(df_balanced)
check_data(df_balanced$data)
check_data(df_shuffled)
## ==== CLASSIFICATION ====
# Shuffle data -----
check_data(df_products)
## ==== CLASSIFICATION ====
# Shuffle data -----
# check_data(df_products)
df_temp <- df_products %>%
select( -c("datetime", "pageNum", "product_id", "product", "producer_id", "producer", "area"))
shuffle_index <- sample(1:nrow(df_temp))
head(shuffle_index)
df_shuffled <- df_temp[shuffle_index,]
head(df_shuffled)
# Separate data for training and testing ----
data_train <- create_train_test(df_shuffled, 0.8, train = TRUE)
data_test <- create_train_test(df_shuffled, 0.8, train = FALSE)
dim(data_train)
dim(data_test)
prop.table(table(data_train$hasGAP))
prop.table(table(data_test$hasGAP))
# Balancing training data ----
df_balanced <- ovun.sample(
hasJAS~.,
data = ,
N = nrow(data_train),
p = 0.5,
seed = 1,
method = "both"
)
# Balancing training data ----
df_balanced <- ovun.sample(
hasJAS~.,
data = data_train,
N = nrow(data_train),
p = 0.5,
seed = 1,
method = "both"
)
# Balancing training data ----
data_train_balanced <- ovun.sample(
hasJAS~.,
data = data_train,
N = nrow(data_train),
p = 0.5,
seed = 1,
method = "both"
)
# Build the model ----
fit <- rpart(hasJAS~., data = data_train_balanced, method = 'class')
# Balancing training data ----
data_train_balanced <- ovun.sample(
hasJAS~.,
data = data_train,
N = nrow(data_train),
p = 0.5,
seed = 1,
method = "both"
)$data
# Build the model ----
fit <- rpart(hasJAS~., data = data_train_balanced, method = 'class')
rpart.plot(fit)
# Make a prediction ----
predict_unseen <- predict(fit,data_test, type = 'class')
# Check accuracy ----
confusionMatrix(predict_unseen, data_test$hasJAS, mode = "everything", positive = "JAS")
# Tune model ----
df_temp <- NULL
rownum <- 1
pb <- new_pb(10^3)
for(i in 1:10) {
for(j in 1:10){
for(k in 1:10) {
pb$tick()
control <- rpart.control(
minsplit = i,
minbucket = j,
maxdepth = k,
cp = 0
)
tune_fit <- rpart(hasJAS~., data = data_train, method = 'class', control = control)
ac <- accuracy_tune(tune_fit)
df_temp$ac[rownum] = ac
df_temp$minsplit[rownum] = i
df_temp$minbucket[rownum] = j
df_temp$maxdepth[rownum] = k
rownum <- rownum + 1
}
}
}
df_temp_raw <- df_temp
df_temp <- as.data.frame(df_temp)
check_data(df_temp)
ggpairs(
df_temp,
lower = list(continuous = "smooth", combo = "facetdensity"),
diag = list(continuous = "barDiag")
)
max_ac <- max(df_temp$ac)
df_max <- df_temp[df_temp$ac == max_ac,]
# check_data(df_max)
for(i in nrow(df_max)) {
minsplit <- df_max$minsplit[i]
minbucket <- df_max$minbucket[i]
maxdepth <- df_max$maxdepth[i]
control <- rpart.control(
minsplit = minsplit,
minbucket = minbucket,
maxdepth = maxdepth,
cp = 0
)
tune_fit <- rpart(hasJAS~., data = data_train, method = 'class', control = control)
(rpart.plot(tune_fit))
}
# Confusion matrix ----
pred <- predict(tune_fit, data_test, type = 'class')
confusionMatrix(pred, data_test$hasJAS, mode = 'everything', positive = "JAS")
